<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>机器学习基石上（第2周）学习笔记--Learning to Answer Yes/No | Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="上一周回顾第一周题目为 The Learning Problem，主要讲了机器学习的定义和应用，并介绍了机器学习流程，如下图所示。训练样本D，使用算法A，在假设模型集中选择最优的，训练后得到 g（假设函数）≈f(目标函数)。本周主要讲解PLA(感知机算法)，即二分类算法之一。 1.Perceptron Hypothesis Set继续以上一周的信用卡申请为例，如下图。银行根据用户的年龄、年收入、工">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习基石上（第2周）学习笔记--Learning to Answer Yes&#x2F;No">
<meta property="og:url" content="http://yoursite.com/2018/04/04/机器学习基石上（第2周）学习笔记/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="上一周回顾第一周题目为 The Learning Problem，主要讲了机器学习的定义和应用，并介绍了机器学习流程，如下图所示。训练样本D，使用算法A，在假设模型集中选择最优的，训练后得到 g（假设函数）≈f(目标函数)。本周主要讲解PLA(感知机算法)，即二分类算法之一。 1.Perceptron Hypothesis Set继续以上一周的信用卡申请为例，如下图。银行根据用户的年龄、年收入、工">
<meta property="og:image" content="https://img-blog.csdn.net/20170607153730795?">
<meta property="og:image" content="https://img-blog.csdn.net/20160512221250323?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center">
<meta property="og:image" content="https://img-blog.csdn.net/20170608083119699?">
<meta property="og:image" content="https://img-blog.csdn.net/20170608084125366?">
<meta property="og:image" content="https://img-blog.csdn.net/20170608095000165?">
<meta property="og:image" content="https://img-blog.csdn.net/20170608102847562?">
<meta property="og:image" content="https://img-blog.csdn.net/20170608104910590?">
<meta property="og:image" content="https://img-blog.csdn.net/20170608104952086?">
<meta property="og:image" content="https://img-blog.csdn.net/20170608105013685?">
<meta property="og:image" content="https://img-blog.csdn.net/20170608105029404?">
<meta property="og:image" content="https://img-blog.csdn.net/20170608105044842?">
<meta property="og:image" content="https://img-blog.csdn.net/20170608105044842?">
<meta property="og:image" content="https://img-blog.csdn.net/20170608105100764?">
<meta property="og:image" content="https://img-blog.csdn.net/20170608105122249?">
<meta property="og:image" content="https://img-blog.csdn.net/20170608105214946?">
<meta property="og:image" content="https://img-blog.csdn.net/20170608105230634?">
<meta property="og:image" content="https://img-blog.csdn.net/20170608105243181?">
<meta property="og:image" content="https://img-blog.csdn.net/20170608105257829?">
<meta property="og:image" content="https://img-blog.csdn.net/20170608111542131?">
<meta property="og:image" content="https://img-blog.csdn.net/20170608134312092?">
<meta property="og:image" content="https://img-blog.csdn.net/20170608134340499?">
<meta property="og:image" content="https://img-blog.csdn.net/20160704161452151?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast">
<meta property="og:image" content="https://img-blog.csdn.net/20170608140302480?">
<meta property="og:image" content="https://img-blog.csdn.net/20160704154757801?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast">
<meta property="og:image" content="https://img-blog.csdn.net/20160704162324944?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center">
<meta property="og:image" content="https://img-blog.csdn.net/20160704163407931?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center">
<meta property="og:image" content="https://img-blog.csdn.net/20160704163907886?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center">
<meta property="og:image" content="https://img-blog.csdn.net/20170608143421951?">
<meta property="og:image" content="https://img-blog.csdn.net/20170608143438779?">
<meta property="og:image" content="https://img-blog.csdn.net/20170608150716294?">
<meta property="og:image" content="https://img-blog.csdn.net/20170608151418751?">
<meta property="og:image" content="https://img-blog.csdn.net/20170608155259223?">
<meta property="og:updated_time" content="2018-04-04T15:09:46.607Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="机器学习基石上（第2周）学习笔记--Learning to Answer Yes&#x2F;No">
<meta name="twitter:description" content="上一周回顾第一周题目为 The Learning Problem，主要讲了机器学习的定义和应用，并介绍了机器学习流程，如下图所示。训练样本D，使用算法A，在假设模型集中选择最优的，训练后得到 g（假设函数）≈f(目标函数)。本周主要讲解PLA(感知机算法)，即二分类算法之一。 1.Perceptron Hypothesis Set继续以上一周的信用卡申请为例，如下图。银行根据用户的年龄、年收入、工">
<meta name="twitter:image" content="https://img-blog.csdn.net/20170607153730795?">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSSフィード"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="検索"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-机器学习基石上（第2周）学习笔记" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/04/04/机器学习基石上（第2周）学习笔记/" class="article-date">
  <time datetime="2018-04-04T13:05:23.000Z" itemprop="datePublished">2018-04-04</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      机器学习基石上（第2周）学习笔记--Learning to Answer Yes/No
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="上一周回顾"><a href="#上一周回顾" class="headerlink" title="上一周回顾"></a>上一周回顾</h1><p>第一周题目为 The Learning Problem，主要讲了机器学习的定义和应用，并介绍了机器学习流程，如下图所示。<br>训练样本D，使用算法A，在假设模型集中选择最优的，训练后得到 g（假设函数）≈f(目标函数)。<br><img src="https://img-blog.csdn.net/20170607153730795?" alt="avatar"><br>本周主要讲解PLA(感知机算法)，即二分类算法之一。</p>
<h1 id="1-Perceptron-Hypothesis-Set"><a href="#1-Perceptron-Hypothesis-Set" class="headerlink" title="1.Perceptron Hypothesis Set"></a>1.Perceptron Hypothesis Set</h1><p>继续以上一周的信用卡申请为例，如下图。银行根据用户的年龄、年收入、工作年限、负债等情况来判断是否给该用户发信用卡。<br><img src="https://img-blog.csdn.net/20160512221250323?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="avatar"><br>现在的训练集D：历史用户的信息和是否发了信用卡。在机器学习流程中，在模型集 H 中选择合适的模型非常重要。下面要讲解的Hypothesis Set:感知机（Perceptron）。</p>
<p>上面的例子，</p>
<pre><code>个人信息 = 特征向量x(i)
有d个信息 = d个特征向量（特征集为d维）
每个特征向量给定权重w(i) =&gt; 该特征向量对结果（是否发信用卡）的影响
加权特征向量的和 &gt; 设定的阈值threshold =&gt; y=1,通过
加权特征向量的和 &lt; 设定的阈值threshold =&gt; y=-1,拒绝
感知机模型 h(x) = （加权特征向量 - 阈值threshold）的正负性
</code></pre><p>从而我们的目标：权值w（d维）和 阈值threshold。</p>
<p>下面对 h(x)转换，令阈值 threshold=w0，引入一个 x0=1 的特征向量与 w0 相乘，这样阈值也成了特征为1的特征向量（即成了个人信息之一），此时为 （d+1）个特征，如下图。<br> <img src="https://img-blog.csdn.net/20170608083119699?" alt="avatar"><br>假设感知机模型在二维平面上，即h(x)=sign(w0+w1x1+w2x2)。其中，w0+w1x1+w2x2=0 是平面上一条分类直线，直线一侧是正类（+1），直线另一侧是负类（-1）。权重w不同，对应于平面上不同的直线。如下图。<br><img src="https://img-blog.csdn.net/20170608084125366?" alt="avatar"><br>在上图中，感知机模型就是一条蓝色的直线，称之为linear(binary) classifiers。在3维中，感知机模型就是平面，在更高维度中，感知机模型（线性分类）用超平面表示，即只要是形如 wTx 的模型就都属于linear(binary) classifiers。</p>
<p>本例的linear(binary) classifiers是用简单的感知器模型建立的，线性分类问题还可以使用logistic regression(逻辑回归)。</p>
<h1 id="2-Perceptron-Learning-Algorithm-PLA"><a href="#2-Perceptron-Learning-Algorithm-PLA" class="headerlink" title="2.Perceptron Learning Algorithm(PLA)"></a>2.Perceptron Learning Algorithm(PLA)</h1><p>通过上一节的介绍，大致了解了感知机模型，在上例中，hypothesis set就是一系列直线。得到的hypothesis set，下一步的目标就是通过算法A找到最优的直线。</p>
<p>为了找到这条最优直线，我们可以使用“逐步修正”，具体如下：</p>
<pre><code>1.在平面上任意取一条直线 h(x)，法向量为w1
2.遍历平面上各点带入 h(x),碰到第一个符号相反的点就停下
3.实际y=+1,而h(x)判断为负，说明直线的 w1 与 x（向量形式）夹角大于90度，进行法向量修正，令 w2 = w1 + x(1),修正后直线的w2 与 x 夹角 小于90度，为正，修正完成。实际y=-1,而h(x)判断为正同理。
4.接着重复2,3步骤，不断迭代，直到所有的点都完全分类正确。
</code></pre><p>下图是步骤3的具体操作。<br><img src="https://img-blog.csdn.net/20170608095000165?" alt="avatar"><br>上面“逐步修正”就是本周重点学习的PLA算法。<br>实际操作中，可以一个点一个点地遍历，发现分类错误的点就进行修正，直到所有点全部分类正确。这种被称为Cyclic PLA。<br><img src="https://img-blog.csdn.net/20170608102847562?" alt="avatar"><br>下面用图解的形式来介绍PLA的修正过程：红色是法向量w,黑色的犯错的点x,紫色为修正的w。<br><img src="https://img-blog.csdn.net/20170608104910590?" alt="avatar"><br><img src="https://img-blog.csdn.net/20170608104952086?" alt="avatar"><br><img src="https://img-blog.csdn.net/20170608105013685?" alt="avatar"><br><img src="https://img-blog.csdn.net/20170608105029404?" alt="avatar"><br><img src="https://img-blog.csdn.net/20170608105044842?" alt="avatar"><br><img src="https://img-blog.csdn.net/20170608105044842?" alt="avatar"><br><img src="https://img-blog.csdn.net/20170608105100764?" alt="avatar"><br><img src="https://img-blog.csdn.net/20170608105122249?" alt="avatar"><br><img src="https://img-blog.csdn.net/20170608105214946?" alt="avatar"><br><img src="https://img-blog.csdn.net/20170608105230634?" alt="avatar"><br><img src="https://img-blog.csdn.net/20170608105243181?" alt="avatar"><br><img src="https://img-blog.csdn.net/20170608105257829?" alt="avatar"><br>对PLA，我们需要考虑以下两个问题：</p>
<ul>
<li>PLA迭代一定会停下来吗？如果线性不可分怎么办？</li>
<li>PLA停下来的时候，是否能保证f≈g？如果没有停下来，是否有f≈g？</li>
</ul>
<p>下面一节对上诉问题给出解决方案。</p>
<h1 id="3-Guarantee-of-PLA"><a href="#3-Guarantee-of-PLA" class="headerlink" title="3.Guarantee of PLA"></a>3.Guarantee of PLA</h1><p>根据PLA的定义，当找到一条直线，能将所有平面上的点都分类正确，那么PLA就停止了。要达到这个终止条件，就必须保证D是线性可分（linear separable）。如果是非线性可分的，那么，PLA就不会停止。如下图。<br><img src="https://img-blog.csdn.net/20170608111542131?" alt="avatar"><br>如果D线性可分，那么存在一条直线可以将正类和负类分开，令这时候的目标权重为wf，即对任一点都有：<br><img src="https://img-blog.csdn.net/20170608134312092?" alt="avatar"><br>PLA会对每次错误的点进行修正，更新权重wt+1的值，如果wt+1与wf越来越接近，数学运算上就是内积越大，那表示wt+1是在接近目标权重wf，证明PLA是有学习效果的。所以，我们来计算wt+1与wf的内积：<br><img src="https://img-blog.csdn.net/20170608134340499?" alt="avatar"><br>从推导可以看出，wt+1与wf的内积跟wt与wf的内积相比更大了。似乎说明了wt+1更接近wf，但是内积更大，可能是向量长度更大了，不一定是向量间角度更小。所以，下一步，我们还需要证明wt+1与wt向量长度的关系：<br><img src="https://img-blog.csdn.net/20160704161452151?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="avatar"><br><img src="https://img-blog.csdn.net/20170608140302480?" alt="avatar"><br>wt只会在分类错误的情况下更新，最终得到的||w2t+1||相比||w2t||的增量值不超过max||x2n||。也就是说，wt的增长被限制了，wt+1与wt向量长度不会差别太大！<br>如果令初始权值w0=0，那么经过T次错误修正后，有如下结论：<br><img src="https://img-blog.csdn.net/20160704154757801?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="avatar"><br>上图中公式1给出了WT的模的求法，并且最终迭代得：<br><img src="https://img-blog.csdn.net/20160704162324944?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="avatar"><br>进一步：<br><img src="https://img-blog.csdn.net/20160704163407931?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="avatar"><br>可以看出权值向量和目标函数内积会以的速度不断的增长，但是这种增长不是没有限制的，它最多只能等于1。<br>进而：<br><img src="https://img-blog.csdn.net/20160704163907886?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="avatar"><br>上面看不懂得，下面贴出了更详细的推导：<br><img src="https://img-blog.csdn.net/20170608143421951?" alt="avatar"><br><img src="https://img-blog.csdn.net/20170608143438779?" alt="avatar"> </p>
<h1 id="4-Non-Separable-Data"><a href="#4-Non-Separable-Data" class="headerlink" title="4.Non-Separable Data"></a>4.Non-Separable Data</h1><p>上节我们证明了线性可分的情况下，迭代是有限的。本节解决线性不可分的情况。如果一个PLA算法运行了很长时间仍然没有停止，此时存在两种可能性，一是该数据集是线性可分的，但是还没有运行结束；另一种，压根就不存在一条直线可以将数据集分开，就是压根这个算法就不会终止。假如是后者又该如何处理？</p>
<p>出现不可分的一种可能是从未知目标函数中产生的训练样本存在噪音（noise），如录入样本时有人工的错误等情况导致数据本身不正确，使得最终本可以线性可分的样本集变得线性不可分了。这时，机器学习流程是这样的：<br><img src="https://img-blog.csdn.net/20170608150716294?" alt="avatar"><br>在非线性情况下，我们可以把条件放松，即不苛求每个点都分类正确，而是容忍有错误点，取错误点的个数最少时的权重w：<br><img src="https://img-blog.csdn.net/20170608151418751?" alt="avatar"><br>事实证明，上面的解是NP-hard问题，难以求解。然而，我们可以对在线性可分类型中表现很好的PLA做个修改，把它应用到非线性可分类型中，获得近似最好的g。</p>
<p>修改后的PLA称为Packet Algorithm。它的算法流程与PLA基本类似，首先初始化权重w0，计算出在这条初始化的直线中，分类错误点的个数。然后对错误点进行修正，更新w，得到一条新的直线，在计算其对应的分类错误的点的个数，并与之前错误点个数比较，取个数较小的直线作为我们当前选择的分类直线。之后，再经过n次迭代，不断比较当前分类错误点个数与之前最少的错误点个数比较，选择最小的值保存。直到迭代次数完成后，选取个数最少的直线对应的w，即为我们最终想要得到的权重值。<br><img src="https://img-blog.csdn.net/20170608155259223?" alt="avatar"><br>如何判断数据集D是不是线性可分？对于二维数据来说，通常还是通过肉眼观察来判断的。一般情况下，Pocket Algorithm要比PLA速度慢一些。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/04/04/机器学习基石上（第2周）学习笔记/" data-id="cjfl3uqmp00004sd6joonjhdt" class="article-share-link">共有</a>
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2018/04/14/机器学习基石（第3周）学习笔记-Types-of-Learning/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">次の記事</strong>
      <div class="article-nav-title">
        
          机器学习基石（第3周）学习笔记--Types of  Learning
        
      </div>
    </a>
  
  
    <a href="/2018/04/01/机器学习基石上（第1周）学习笔记/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">前の記事</strong>
      <div class="article-nav-title">机器学习基石上（第1周）学习笔记--The learning Problem</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">タグ</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/markdown/">markdown</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/机器学习/">机器学习</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">タグクラウド</h3>
    <div class="widget tagcloud">
      <a href="/tags/markdown/" style="font-size: 10px;">markdown</a> <a href="/tags/机器学习/" style="font-size: 10px;">机器学习</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">アーカイブ</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/04/">April 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/03/">March 2018</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">最近の投稿</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2018/04/14/机器学习基石（第3周）学习笔记-Types-of-Learning/">机器学习基石（第3周）学习笔记--Types of  Learning</a>
          </li>
        
          <li>
            <a href="/2018/04/04/机器学习基石上（第2周）学习笔记/">机器学习基石上（第2周）学习笔记--Learning to Answer Yes/No</a>
          </li>
        
          <li>
            <a href="/2018/04/01/机器学习基石上（第1周）学习笔记/">机器学习基石上（第1周）学习笔记--The learning Problem</a>
          </li>
        
          <li>
            <a href="/2018/03/26/Hello-github/">Markdowm简明语法学习</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2018 John Doe<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
</body>
</html>